---
title: 'Web Scraping con R '
author: Eddy Cáceres
date: '2019-09-21'
slug: web-scraping-in-r
categories:
  - R
tags: ["scraping", "plotly", "javascript"]
description: ''
thumbnail: 'post/img/webscraping.png'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```


# Obten datos de una pagina web dinámica


Una de las cosas interesantes cuando se analiza datos es querer comparar datos propios con datos abiertos de la web, lo que conocemos como Web Scraping. Cuando iniciamos nuestro primer objetivo son las páginas que tienen los datos en texto plano Html, en R con el uso de la librería **Rvest** nos es relativamente sencillo obtener los datos en un dataframe y luego trabajar en con ellas. Pero, ¿Qué pasa con las páginas que para mostrar sus datos ejecutan primero un código JavaScript?

En este tutorial veremos como obtener datos desde este tipo de páginas combinando las bondades de Phantomjs y el ya mencionado Rvest. El ejemplo consiste en obtener los datos del **Comité de Operación Económica del Sistema Interconectado Nacional (COES)** y graficaremos el resultado.


Instalar dependencias:

1. Instalar Rvest : __install.packages(“rvest”)__
2. Descargar Phantomjs : <https://phantomjs.org/download.html>


En el caso de Windows ubicar el instalador en el directorio donde se encuentra el programa. Necesitamos ejecutar el código JavaScript que contiene la página para renderizar los datos y lo hacemos con el siguiente código, lo llamaremos __"scrape_page.js"__

```{r eval=FALSE}
var webPage = require('webpage');
var page = webPage.create();
var fs = require('fs');
var path = 'coes.html'
page.open('https://www.coes.org.pe/Portal/portalinformacion/demanda', function (status) {
  var content = page.content;
  fs.write(path,content,'w')
  phantom.exit();
});
```


En R escribimos el __"script scrape_data.R"__ para ejecutar el JavaScript.  y almacenar la información


```{r warning=FALSE,message=FALSE}
library(rvest)
library(tidyverse)
library(stringi)

#path to executable phantomjs
#system("C:\..\\phantomjs.exe scrape_coes.js")

paginawebca<-read_html("../../coes.html")
selectorca<-"#contentHolder > table"
nodo_tabla<-html_node(paginawebca,selectorca)
nodo_tabla<-html_table(nodo_tabla)

```


Tienes que posicionarte en el directorio donde se encuentra el ejecutable. Phamtonjs renderizará los datos de la página y lo escribe en un archivo html, después con rvest buscamos la tabla de nuestro interés lo convertimos a un dataframe

```{r warning=FALSE,message=FALSE}
head(nodo_tabla)

```

Filtramos los datos que deseamos


```{r warning=FALSE,message=FALSE}
#choosing data to graph
data <- nodo_tabla[1:48,]
data$Fecha <- str_replace_all(data$Fecha, "/", "-")
data$Fecha <- as.character(strptime(as.character(data$Fecha),"%d-%m-%Y %H:%M"))
data[2:4] <-data %>% select(2:4)%>%
  mutate_all(str_replace_all," ","")%>%
  mutate_all(str_replace_all,",",".")
```
 Y el gráfico que obtenemos es 
 
```{r warning=FALSE,message=FALSE}
#ploting values 
library(plotly)
library(dplyr)

dates1 <- strptime(as.character(data$Fecha), "%Y-%m-%d %H:%M:%S")
data <- data[,2:ncol(data)]  #tomamos la parte del dataframe con los valores
data <- data.frame(date=dates1,data)  #Añadimos las fechas

plot_ly(data,x = ~date)%>%
  add_lines(y=data$Ejecutado, name=colnames(data)[2])%>%
  add_lines(y=data$Prog..Diaria,name=colnames(data)[3])%>%
  add_lines(y=data$Prog..Semanal,name=colnames(data)[4])
```


Ppppuedes descargar el código fuente [aqui ](https://www.google.com).  No olvides descargar y posicionar el ejecutable de phantomjs. 
